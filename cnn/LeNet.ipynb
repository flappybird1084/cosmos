{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "Vhm4Appxtk2o",
        "outputId": "b6e6a133-7a26-4b12-b453-d6198adce5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.4154336976060179\n",
            "Epoch 2, Loss: 0.07222254855681394\n",
            "Epoch 3, Loss: 0.04789216577761503\n",
            "Epoch 4, Loss: 0.03817828495858678\n",
            "Epoch 5, Loss: 0.031972201243946466\n",
            "Epoch 6, Loss: 0.025068651214537364\n",
            "Epoch 7, Loss: 0.02281774694177529\n",
            "Epoch 8, Loss: 0.01850628656561707\n",
            "Epoch 9, Loss: 0.01708058454756816\n",
            "Epoch 10, Loss: 0.014654421107933498\n",
            "Epoch 11, Loss: 0.013045212792686472\n",
            "Epoch 12, Loss: 0.011552527098342725\n",
            "Epoch 13, Loss: 0.00979863452194782\n",
            "Epoch 14, Loss: 0.008139286868297254\n",
            "Epoch 15, Loss: 0.009538917465668106\n",
            "Epoch 16, Loss: 0.008277389300412115\n",
            "Epoch 17, Loss: 0.00523607612924169\n",
            "Epoch 18, Loss: 0.005359907771049098\n",
            "Epoch 19, Loss: 0.004902569789266196\n",
            "Epoch 20, Loss: 0.005691456429830357\n",
            "Accuracy of the network on the 10000 test images: 99.06%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Define LeNet model\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "net = LeNet()\n",
        "\n",
        "# Move the model to the device\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
        "\n",
        "# Plot the learned weight kernels for the first feature layer\n",
        "weights = net.conv1.weight.data.cpu().numpy()\n",
        "fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(weights[i, 0, :, :], cmap='viridis')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
