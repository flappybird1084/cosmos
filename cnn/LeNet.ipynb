{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "Vhm4Appxtk2o",
        "outputId": "b6e6a133-7a26-4b12-b453-d6198adce5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.4072069679118836\n",
            "Epoch 2, Loss: 0.0730000718989209\n",
            "Epoch 3, Loss: 0.050272888038245374\n",
            "Epoch 4, Loss: 0.03834175855820643\n",
            "Epoch 5, Loss: 0.031808015713996905\n",
            "Epoch 6, Loss: 0.02627363925016856\n",
            "Epoch 7, Loss: 0.02268535529809961\n",
            "Epoch 8, Loss: 0.01921416265254062\n",
            "Epoch 9, Loss: 0.015612099037058827\n",
            "Epoch 10, Loss: 0.01312973604791414\n",
            "Epoch 11, Loss: 0.011069351141081252\n",
            "Epoch 12, Loss: 0.011836250081054272\n",
            "Epoch 13, Loss: 0.0108285993652648\n",
            "Epoch 14, Loss: 0.008119265690254573\n",
            "Epoch 15, Loss: 0.006820263045846805\n",
            "Epoch 16, Loss: 0.005218349649639965\n",
            "Epoch 17, Loss: 0.004740477085138596\n",
            "Epoch 18, Loss: 0.0035009918106061935\n",
            "Epoch 19, Loss: 0.003818558992360971\n",
            "Epoch 20, Loss: 0.008616927398882509\n",
            "Accuracy of the network on the 10000 test images: 99.05%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Define LeNet model\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "net = LeNet()\n",
        "\n",
        "# Move the model to the device\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
        "\n",
        "# Plot the learned weight kernels for the first feature layer\n",
        "weights = net.conv1.weight.data.cpu().numpy()\n",
        "fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(weights[i, 0, :, :], cmap='viridis')\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
