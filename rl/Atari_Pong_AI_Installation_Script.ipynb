{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UfDj0WdFVOzB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Robust Installation for Atari Pong ---\n",
            "\n",
            "0. Upgrading pip...\n",
            "Requirement already satisfied: pip in ./env/lib/python3.11/site-packages (25.1.1)\n",
            "\n",
            "1. Installing/Upgrading ale-py and gymnasium[atari]...\n",
            "Requirement already satisfied: ale-py in ./env/lib/python3.11/site-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in ./env/lib/python3.11/site-packages (from ale-py) (2.1.3)\n",
            "Requirement already satisfied: gymnasium[atari] in ./env/lib/python3.11/site-packages (1.1.1)\n",
            "Collecting gymnasium[atari]\n",
            "  Using cached gymnasium-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in ./env/lib/python3.11/site-packages (from gymnasium[atari]) (2.1.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in ./env/lib/python3.11/site-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./env/lib/python3.11/site-packages (from gymnasium[atari]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in ./env/lib/python3.11/site-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in ./env/lib/python3.11/site-packages (from gymnasium[atari]) (0.11.2)\n",
            "Using cached gymnasium-1.2.0-py3-none-any.whl (944 kB)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "stable-baselines3 2.6.0 requires gymnasium<1.2.0,>=0.29.1, but you have gymnasium 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-1.2.0\n",
            "\n",
            "2. Installing/Upgrading stable-baselines3...\n",
            "Requirement already satisfied: stable-baselines3 in ./env/lib/python3.11/site-packages (2.6.0)\n",
            "Collecting gymnasium<1.2.0,>=0.29.1 (from stable-baselines3)\n",
            "  Using cached gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in ./env/lib/python3.11/site-packages (from stable-baselines3) (2.1.3)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in ./env/lib/python3.11/site-packages (from stable-baselines3) (2.7.1)\n",
            "Requirement already satisfied: cloudpickle in ./env/lib/python3.11/site-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in ./env/lib/python3.11/site-packages (from stable-baselines3) (2.3.1)\n",
            "Requirement already satisfied: matplotlib in ./env/lib/python3.11/site-packages (from stable-baselines3) (3.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./env/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in ./env/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in ./env/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in ./env/lib/python3.11/site-packages (from triton==3.3.1->torch<3.0,>=2.3->stable-baselines3) (80.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.11/site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.11/site-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.11/site-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Using cached gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "Successfully installed gymnasium-1.1.1\n",
            "\n",
            "3. Installing AutoROM...\n",
            "Requirement already satisfied: autorom[accept-rom-license] in ./env/lib/python3.11/site-packages (0.4.2)\n",
            "Requirement already satisfied: click in ./env/lib/python3.11/site-packages (from autorom[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in ./env/lib/python3.11/site-packages (from autorom[accept-rom-license]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in ./env/lib/python3.11/site-packages (from autorom[accept-rom-license]) (4.67.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in ./env/lib/python3.11/site-packages (from autorom[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests->autorom[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests->autorom[accept-rom-license]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests->autorom[accept-rom-license]) (2025.7.9)\n",
            "\n",
            "4. Running AutoROM.build() to download Atari ROMs. This may take a moment...\n",
            "Look for messages indicating ROMs are being downloaded/accepted.\n",
            "/home/software/Documents/.rianstuff/cosmos/env/bin/python: Error while finding module specification for 'autorom.accept-rom-license' (ModuleNotFoundError: No module named 'autorom')\n",
            "\n",
            "5. Installing opencv-python...\n",
            "Requirement already satisfied: opencv-python in ./env/lib/python3.11/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in ./env/lib/python3.11/site-packages (from opencv-python) (2.1.3)\n",
            "\n",
            "--- Installation Steps Completed ---\n",
            "\n",
            "--- Running Robust Environment Test for 'ALE/Pong-v5' ---\n",
            "Successfully imported ale_py version: 0.11.2\n",
            "Successfully created and reset 'ALE/Pong-v5' environment.\n",
            "This indicates that the Atari ROMs and dependencies are likely set up correctly.\n",
            "\n",
            "SUCCESS: You can now proceed to the training script in a new cell.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n"
          ]
        }
      ],
      "source": [
        "# @title Atari Pong AI - Installation Script (More Robust)\n",
        "\n",
        "# This script aims to provide the most robust installation for Atari Pong\n",
        "# using Stable Baselines3 and Gymnasium in Google Colab.\n",
        "\n",
        "# IMPORTANT:\n",
        "# 1. Start with a FRESH COLAB NOTEBOOK (Runtime -> Restart runtime).\n",
        "# 2. Run this cell FIRST and wait for it to complete.\n",
        "# 3. Carefully observe ALL output.\n",
        "# 4. If the \"Quick Environment Test\" at the end FAILS, go to \"Runtime -> Restart runtime\"\n",
        "#    and run *this entire cell again from scratch*. This is often necessary.\n",
        "# 5. If it still fails after a couple of restarts and reruns, please share the FULL output.\n",
        "\n",
        "print(\"--- Starting Robust Installation for Atari Pong ---\")\n",
        "\n",
        "# 0. Ensure pip is up-to-date\n",
        "print(\"\\n0. Upgrading pip...\")\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# 1. Install/Upgrade core Gymnasium and specific ale-py.\n",
        "#    `gymnasium` is the successor to `gym`.\n",
        "#    We explicitly install `ale-py` and then `gymnasium[atari]` to ensure order.\n",
        "print(\"\\n1. Installing/Upgrading ale-py and gymnasium[atari]...\")\n",
        "# Install ale-py first, explicitly, to ensure it's present for gymnasium[atari]\n",
        "!pip install --upgrade ale-py\n",
        "# Then install gymnasium with atari extras, which should now find ale-py\n",
        "!pip install --upgrade gymnasium[atari]\n",
        "\n",
        "# 2. Install Stable Baselines3 (SB3).\n",
        "print(\"\\n2. Installing/Upgrading stable-baselines3...\")\n",
        "!pip install --upgrade stable-baselines3\n",
        "\n",
        "# 3. Install AutoROM.\n",
        "#    This is CRUCIAL for Atari ROM management.\n",
        "print(\"\\n3. Installing AutoROM...\")\n",
        "!pip install autorom[accept-rom-license]\n",
        "\n",
        "# 4. Run AutoROM.build() to download Atari ROMs.\n",
        "#    This command needs to be run explicitly. This is the most common point of failure.\n",
        "print(\"\\n4. Running AutoROM.build() to download Atari ROMs. This may take a moment...\")\n",
        "print(\"Look for messages indicating ROMs are being downloaded/accepted.\")\n",
        "!python -m autorom.accept-rom-license\n",
        "\n",
        "# 5. Install OpenCV Python (cv2).\n",
        "print(\"\\n5. Installing opencv-python...\")\n",
        "!pip install --upgrade opencv-python\n",
        "\n",
        "print(\"\\n--- Installation Steps Completed ---\")\n",
        "\n",
        "# --- Robust Environment Test ---\n",
        "# This test attempts to create the Pong environment to verify installation.\n",
        "print(\"\\n--- Running Robust Environment Test for 'ALE/Pong-v5' ---\")\n",
        "try:\n",
        "    import gymnasium as gym\n",
        "    # Try importing ale_py directly to check if it's found\n",
        "    try:\n",
        "        import ale_py\n",
        "        print(f\"Successfully imported ale_py version: {ale_py.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"ERROR: Could not import 'ale_py'. This indicates a fundamental installation issue.\")\n",
        "        raise\n",
        "\n",
        "    # Attempt to make the environment\n",
        "    env_test = gym.make(\"ALE/Pong-v5\")\n",
        "    env_test.reset()\n",
        "    env_test.close()\n",
        "    print(f\"Successfully created and reset 'ALE/Pong-v5' environment.\")\n",
        "    print(\"This indicates that the Atari ROMs and dependencies are likely set up correctly.\")\n",
        "    print(\"\\nSUCCESS: You can now proceed to the training script in a new cell.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nFATAL ERROR: Failed to create 'ALE/Pong-v5' environment during test: {e}\")\n",
        "    print(\"This error means the Atari ROMs or the 'ale-py' library are NOT correctly set up.\")\n",
        "    print(\"\\n--- TROUBLESHOOTING STEPS ---\")\n",
        "    print(\"1. Go to 'Runtime -> Restart runtime' in the Colab menu.\")\n",
        "    print(\"2. Run *this entire installation cell* again from scratch.\")\n",
        "    print(\"3. Carefully verify the output of `!python -m autorom.accept-rom-license` for ROM downloads.\")\n",
        "    print(\"4. If the error persists after 2-3 attempts, consider trying a different Colab instance or reporting the full error output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dv4Qcap6WYup"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-21 14:49:33.381278: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-21 14:49:33.485231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753134573.525056 3870342 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753134573.536612 3870342 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1753134573.624591 3870342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753134573.624602 3870342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753134573.624603 3870342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753134573.624604 3870342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-21 14:49:33.636002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training for ALE/Pong-v5 ---\n",
            "Logs and models will be saved in: data/pong_ppo_logs/\n",
            "Total timesteps: 100000\n",
            "Number of parallel environments: 4\n",
            "Successfully created vectorized environment for ALE/Pong-v5\n",
            "PPO model initialized with CnnPolicy and reduced CNN features.\n",
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Checkpoint callback set to save every 100000 total timesteps.\n",
            "\n",
            "--- Starting Training Process ---\n",
            "Logging to data/pong_ppo_logs/PPO_10\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d8a4b8de2a6475091461a80770307b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.torch_layers import NatureCNN\n",
        "from torch import nn\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "\n",
        "# @title Atari Pong AI - Training Script (Saving to Google Drive)\n",
        "\n",
        "# This script trains an AI agent to play Atari Pong using Stable Baselines3 (PPO algorithm)\n",
        "# and Gymnasium. It saves the trained models directly to Google Drive.\n",
        "\n",
        "# IMPORTANT:\n",
        "# 1. Run the installation script first and ensure it completes successfully.\n",
        "# 2. When prompted, authorize Google Colab to access your Google Drive.\n",
        "\n",
        "import gymnasium as gym\n",
        "# import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "import os\n",
        "\n",
        "# # --- 0. Mount Google Drive ---\n",
        "# print(\"--- Mounting Google Drive ---\")\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# # print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "# # --- Configuration ---\n",
        "ENV_ID = \"ALE/Pong-v5\"  # The Gymnasium ID for Atari Pong\n",
        "\n",
        "# # Set the log directory to a path within your Google Drive\n",
        "# # This will create a folder named 'pong_ppo_logs' directly in your MyDrive root.\n",
        "LOG_DIR = \"data/pong_ppo_logs/\"\n",
        "TOTAL_TIMESTEPS = 100_000  # Total number of timesteps for training (increased for Pong)\n",
        "SAVE_FREQ = 100_000  # Save model every X timesteps\n",
        "N_ENVS = 4  # Number of parallel environments to run for vectorized training\n",
        "\n",
        "# Create log directory in Google Drive if it doesn't exist\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"--- Starting Training for {ENV_ID} ---\")\n",
        "print(f\"Logs and models will be saved in: {LOG_DIR}\")\n",
        "print(f\"Total timesteps: {TOTAL_TIMESTEPS}\")\n",
        "print(f\"Number of parallel environments: {N_ENVS}\")\n",
        "\n",
        "# --- Environment Setup ---\n",
        "# Create a vectorized environment. This speeds up training by running multiple\n",
        "# environments in parallel.\n",
        "# For Atari, SB3 automatically applies necessary wrappers (e.g., frame stacking,\n",
        "# grayscale, resizing) when using CnnPolicy.\n",
        "try:\n",
        "    vec_env = make_vec_env(ENV_ID, n_envs=N_ENVS, seed=0)\n",
        "    FRAME_STACK=10\n",
        "    vec_env = VecFrameStack(vec_env, n_stack=FRAME_STACK)\n",
        "    print(f\"Successfully created vectorized environment for {ENV_ID}\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Failed to create environment '{ENV_ID}': {e}\")\n",
        "    print(\"This error almost always means the Atari ROMs are not correctly installed or recognized.\")\n",
        "    print(\"Please go back to the installation cell, ensure it runs without errors,\")\n",
        "    print(\"and specifically check the output of `!python -m autorom.accept-rom-license`.\")\n",
        "    print(\"You might need to restart the Colab runtime (Runtime -> Restart runtime) and run the installation cell again, then this training cell.\")\n",
        "    exit() # Exit if environment creation fails, as training cannot proceed.\n",
        "\n",
        "# --- Model Definition ---\n",
        "# PPO (Proximal Policy Optimization) is a robust and widely used algorithm\n",
        "# for continuous and discrete action spaces.\n",
        "# `CnnPolicy` is used for environments with image observations (like Atari).\n",
        "# `verbose=1` prints training progress.\n",
        "# `tensorboard_log` enables logging to TensorBoard for visualization.\n",
        "class SmallerCNN(NatureCNN):\n",
        "    def __init__(self, observation_space, features_dim=256 // 2):\n",
        "        super().__init__(observation_space, features_dim=features_dim)\n",
        "\n",
        "# Use the smaller CNN in the PPO policy\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=SmallerCNN\n",
        ")\n",
        "\n",
        "print(\"PPO model initialized with CnnPolicy and reduced CNN features.\")\n",
        "model = PPO(\n",
        "    \"CnnPolicy\",\n",
        "    vec_env,\n",
        "    policy_kwargs=policy_kwargs,\n",
        "    gamma=0.90,\n",
        "    n_steps=2048,\n",
        "    learning_rate=2.5e-4,\n",
        "    ent_coef=0.01,\n",
        "    clip_range=0.2,\n",
        "    gae_lambda=0.95,\n",
        "    n_epochs=5,\n",
        "    verbose=1,\n",
        "    tensorboard_log=LOG_DIR,\n",
        "    device=\"auto\"\n",
        ")\n",
        "\n",
        "# print(\"PPO model initialized with CnnPolicy.\")\n",
        "# model = PPO(\n",
        "#     \"CnnPolicy\",\n",
        "#     vec_env,\n",
        "#     gamma=0.90,\n",
        "#     n_steps=2048,\n",
        "#     learning_rate=2.5e-4,\n",
        "#     ent_coef=0.01,\n",
        "#     clip_range=0.2,\n",
        "#     gae_lambda=0.95,\n",
        "#     n_epochs=5,\n",
        "#     verbose=1,\n",
        "#     tensorboard_log=LOG_DIR,\n",
        "#     # device=\"auto\" # Automatically uses GPU if available, otherwise CPU\n",
        "# )\n",
        "# --- Callbacks ---\n",
        "# CheckpointCallback saves the model periodically during training.\n",
        "# This allows you to resume training or evaluate intermediate models.\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=max(SAVE_FREQ // N_ENVS, 1), # save_freq is in terms of environment steps, not total timesteps\n",
        "    save_path=LOG_DIR,\n",
        "    name_prefix=\"pong_ppo_model\"\n",
        ")\n",
        "print(f\"Checkpoint callback set to save every {SAVE_FREQ} total timesteps.\")\n",
        "\n",
        "# --- Training ---\n",
        "print(\"\\n--- Starting Training Process ---\")\n",
        "try:\n",
        "    model.learn(\n",
        "        total_timesteps=TOTAL_TIMESTEPS,\n",
        "        callback=checkpoint_callback,\n",
        "        progress_bar=True # Shows a progress bar in Colab\n",
        "    )\n",
        "    print(\"\\nTraining completed!\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred during training: {e}\")\n",
        "\n",
        "# --- Save Final Model ---\n",
        "final_model_path = os.path.join(LOG_DIR, \"pong_ppo_final_model\")\n",
        "model.save(final_model_path)\n",
        "print(f\"Final model saved to: {final_model_path}.zip\")\n",
        "\n",
        "# --- Optional: Evaluate the trained agent (after training) ---\n",
        "print(\"\\n--- Evaluation (Optional) ---\")\n",
        "print(\"Loading the final trained model for evaluation...\")\n",
        "try:\n",
        "    # Load the trained model\n",
        "    loaded_model = PPO.load(final_model_path)\n",
        "\n",
        "    # Create a separate environment for evaluation (without vectorization)\n",
        "    eval_env = gym.make(ENV_ID, render_mode=\"rgb_array\") # Use rgb_array for rendering frames\n",
        "    obs, info = eval_env.reset()\n",
        "    print(\"Evaluation environment created.\")\n",
        "\n",
        "    num_episodes = 5\n",
        "    for episode in range(num_episodes):\n",
        "        episode_reward = 0\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        obs, info = eval_env.reset()\n",
        "        print(f\"Starting evaluation episode {episode + 1}/{num_episodes}...\")\n",
        "        while not terminated and not truncated:\n",
        "            action, _states = loaded_model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
        "            episode_reward += reward\n",
        "            # You can optionally render frames here if you want to save a video\n",
        "            # frame = eval_env.render() # This would return an array, you'd need to save it\n",
        "        print(f\"Episode {episode + 1} finished with reward: {episode_reward}\")\n",
        "    eval_env.close()\n",
        "    print(\"Evaluation complete.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during evaluation: {e}\")\n",
        "    print(\"Evaluation skipped. You can manually load and evaluate the model later.\")\n",
        "\n",
        "print(\"\\nTo view training progress, you can use TensorBoard:\")\n",
        "print(f\"Load TensorBoard in a new Colab cell with: %load_ext tensorboard\")\n",
        "print(f\"Then run: %tensorboard --logdir {LOG_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkPW8bS1eoU4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Video Recording for ALE/Pong-v5 ---\n",
            "Loading model from: ./data/pong_ppo_logs/pong_ppo_final_model.zip\n",
            "Video will be saved to: ./pong_game_videos/\n",
            "Model loaded successfully!\n",
            "Environment 'ALE/Pong-v5' created and wrapped for video recording.\n",
            "\n",
            "Starting game episode and recording video...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/software/Documents/.rianstuff/cosmos/pong_game_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Game episode finished. Total reward: -16.0\n",
            "Environment closed. Video recording finalized.\n",
            "\n",
            "--- Video Saved! ---\n",
            "Your video should be saved in the './pong_game_videos/' directory on the Colab runtime disk.\n",
            "To download it:\n",
            "1. Click the 'Files' icon (folder icon) on the left sidebar in Colab.\n",
            "2. Navigate into the './pong_game_videos/' folder.\n",
            "3. Look for a file named something like 'pong_agent_game-episode-0.mp4'.\n",
            "4. Right-click on the video file and select 'Download'.\n",
            "\n",
            "Remember: Colab runtime disk is temporary. Download your video before the session ends!\n"
          ]
        }
      ],
      "source": [
        "# @title Record Atari Pong Game Video\n",
        "\n",
        "# This script loads a trained Stable Baselines3 model for Atari Pong\n",
        "# from the Colab runtime disk and records a video of its gameplay.\n",
        "\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "ENV_ID = \"ALE/Pong-v5\"  # The Gymnasium ID for Atari Pong\n",
        "\n",
        "# Path to the trained model on the Colab runtime disk\n",
        "# This assumes your training script saved the final model here.\n",
        "MODEL_PATH_ON_RUNTIME_DISK = \"./data/pong_ppo_logs/pong_ppo_final_model.zip\"\n",
        "\n",
        "# Directory where the video will be saved on the Colab runtime disk\n",
        "VIDEO_DIR = \"./pong_game_videos/\"\n",
        "VIDEO_PREFIX = \"pong_agent_game\" # Prefix for the video filename\n",
        "\n",
        "# Create the video directory if it doesn't exist\n",
        "os.makedirs(VIDEO_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"--- Starting Video Recording for {ENV_ID} ---\")\n",
        "print(f\"Loading model from: {MODEL_PATH_ON_RUNTIME_DISK}\")\n",
        "print(f\"Video will be saved to: {VIDEO_DIR}\")\n",
        "\n",
        "# --- Load the Trained Model ---\n",
        "try:\n",
        "    model = PPO.load(MODEL_PATH_ON_RUNTIME_DISK)\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load model from {MODEL_PATH_ON_RUNTIME_DISK}: {e}\")\n",
        "    print(\"Please ensure the training script completed and saved the model to this path.\")\n",
        "    print(\"If you restarted the runtime, the model might have been deleted. You might need to re-run training or load from Google Drive.\")\n",
        "    exit() # Exit if model cannot be loaded\n",
        "\n",
        "# --- Create Environment with Video Recording Wrapper ---\n",
        "# The RecordVideo wrapper will automatically save a video of the episode.\n",
        "# `video_folder`: directory to save videos.\n",
        "# `episode_trigger`: records every episode (here, we only run one).\n",
        "# `disable_logger`: disables verbose logging from the wrapper.\n",
        "# try:\n",
        "    # We need render_mode=\"rgb_array\" for video recording\n",
        "env = gym.make(ENV_ID, render_mode=\"rgb_array\")\n",
        "env = RecordVideo(\n",
        "    env,\n",
        "    video_folder=VIDEO_DIR,\n",
        "    episode_trigger=lambda x: True, # Record every episode\n",
        "    name_prefix=VIDEO_PREFIX,\n",
        "    disable_logger=True # Suppress some logging messages from RecordVideo\n",
        ")\n",
        "print(f\"Environment '{ENV_ID}' created and wrapped for video recording.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"ERROR: Could not create environment or video wrapper: {e}\")\n",
        "#     print(\"Ensure gymnasium and its Atari dependencies are correctly installed.\")\n",
        "#     exit()\n",
        "\n",
        "# --- Play One Episode and Record ---\n",
        "print(\"\\nStarting game episode and recording video...\")\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "truncated = False\n",
        "episode_reward = 0\n",
        "\n",
        "\n",
        "while not done and not truncated:\n",
        "    action, _states = model.predict(obs, deterministic=True) # deterministic=True for consistent playback\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "\n",
        "print(f\"\\nGame episode finished. Total reward: {episode_reward}\")\n",
        "\n",
        "# --- Close Environment and Finalize Video ---\n",
        "env.close() # This is crucial for the RecordVideo wrapper to finalize the video file.\n",
        "print(\"Environment closed. Video recording finalized.\")\n",
        "\n",
        "# --- Instructions for Downloading Video ---\n",
        "print(\"\\n--- Video Saved! ---\")\n",
        "print(f\"Your video should be saved in the '{VIDEO_DIR}' directory on the Colab runtime disk.\")\n",
        "print(\"To download it:\")\n",
        "print(\"1. Click the 'Files' icon (folder icon) on the left sidebar in Colab.\")\n",
        "print(f\"2. Navigate into the '{VIDEO_DIR}' folder.\")\n",
        "print(f\"3. Look for a file named something like '{VIDEO_PREFIX}-episode-0.mp4'.\")\n",
        "print(\"4. Right-click on the video file and select 'Download'.\")\n",
        "print(\"\\nRemember: Colab runtime disk is temporary. Download your video before the session ends!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
