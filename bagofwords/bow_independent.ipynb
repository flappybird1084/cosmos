{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d3b9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Colab cell 1: Install & import\n",
    "!pip install --quiet tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a73b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 2: Load IMDB reviews (raw text) via TFDS\n",
    "ds_train = tfds.load('imdb_reviews', split='train', as_supervised=True)\n",
    "ds_test  = tfds.load('imdb_reviews', split='test',  as_supervised=True)\n",
    "\n",
    "train_texts, train_labels = [], []\n",
    "for text, label in tfds.as_numpy(ds_train):\n",
    "    train_texts.append(text.decode('utf-8'))\n",
    "    train_labels.append(int(label))\n",
    "\n",
    "test_texts, test_labels = [], []\n",
    "for text, label in tfds.as_numpy(ds_test):\n",
    "    test_texts.append(text.decode('utf-8'))\n",
    "    test_labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38b4d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 25000, Test samples: 25000\n",
      "data head: [\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", 'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {len(train_texts)}, Test samples: {len(test_texts)}\")\n",
    "print(f\"data head: {train_texts[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f33f73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"Clean text by removing HTML tags, special characters, and extra spaces.\"\"\"\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text.lower()  # Convert to lowercase\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize text into words.\"\"\"\n",
    "    #print(\"cleaning text\")\n",
    "    text = clean(text)\n",
    "    #print(\"tokenizing text\")\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def build_vocabulary(texts, vocab_size=10000):\n",
    "    for text in texts:\n",
    "        tokens = tokenize(text)\n",
    "        counter = Counter(tokens)\n",
    "        vocab = {}\n",
    "        for word, count in counter.most_common(vocab_size):\n",
    "            vocab[word] = count\n",
    "          \n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocabulary(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0aa9223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bow(text, vocab):\n",
    "  tokens = tokenize(text)\n",
    "  bow = np.zeros(len(vocab), dtype=np.float32)\n",
    "  for token in tokens:\n",
    "    if token in vocab:\n",
    "        index = list(vocab.keys()).index(token)\n",
    "        bow[index] += 1\n",
    "  return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27092d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        bow = text_to_bow(text, self.vocab)\n",
    "        return torch.tensor(bow, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52b0fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = IMDBDataset(train_texts, train_labels, vocab)\n",
    "test_dataset = IMDBDataset(test_texts, test_labels, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3af36063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units=128):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(hidden_units, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(input_size=len(vocab), hidden_units=256).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "338d8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, criterion, optimizer, device, epochs=10):\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      for inputs, labels in loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "      print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b5616ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a061dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 25000, Test samples: 25000\n",
      "Epoch [1/25], Loss: 0.6011\n",
      "Epoch [2/25], Loss: 0.5562\n",
      "Epoch [3/25], Loss: 0.5457\n",
      "Epoch [4/25], Loss: 0.5378\n",
      "Epoch [5/25], Loss: 0.5338\n",
      "Epoch [6/25], Loss: 0.5295\n",
      "Epoch [7/25], Loss: 0.5263\n",
      "Epoch [8/25], Loss: 0.5203\n",
      "Epoch [9/25], Loss: 0.5152\n",
      "Epoch [10/25], Loss: 0.5095\n",
      "Epoch [11/25], Loss: 0.5062\n",
      "Epoch [12/25], Loss: 0.5006\n",
      "Epoch [13/25], Loss: 0.4947\n",
      "Epoch [14/25], Loss: 0.4901\n",
      "Epoch [15/25], Loss: 0.4858\n",
      "Epoch [16/25], Loss: 0.4805\n",
      "Epoch [17/25], Loss: 0.4748\n",
      "Epoch [18/25], Loss: 0.4686\n",
      "Epoch [19/25], Loss: 0.4668\n",
      "Epoch [20/25], Loss: 0.4611\n",
      "Epoch [21/25], Loss: 0.4578\n",
      "Epoch [22/25], Loss: 0.4519\n",
      "Epoch [23/25], Loss: 0.4502\n",
      "Epoch [24/25], Loss: 0.4424\n",
      "Epoch [25/25], Loss: 0.4371\n",
      "Accuracy: 0.7263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72     12500\n",
      "           1       0.72      0.74      0.73     12500\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.73      0.73      0.73     25000\n",
      "weighted avg       0.73      0.73      0.73     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {len(train_texts)}, Test samples: {len(test_texts)}\")\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=25)\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620ebf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: tensor([[ 0.0619, -0.0499]], device='mps:0')\n",
      "Sample text sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# test the model with a sample text\n",
    "sample_text = \"This movie was fantastic! I loved it\"\n",
    "sample_text_a = \"good good good good good\"\n",
    "sample_bow = text_to_bow(sample_text, vocab)\n",
    "sample_tensor = torch.tensor(sample_bow, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(sample_tensor)\n",
    "    print(f\"Raw output: {output}\")\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    sentiment = \"Positive\" if predicted.item() == 1 else \"Negative\"\n",
    "    print(f\"Sample text sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573046f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
