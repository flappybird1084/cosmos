{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ae6ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything ml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import contractions\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1bc306a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dataset = pd.read_csv(\"./data/fakenews/True.csv\")\n",
    "false_dataset = pd.read_csv(\"./data/fakenews/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9e8a0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_randomize_datasets(true_dataset, false_dataset):\n",
    "    true_arr = np.ones(len(true_dataset))\n",
    "    false_arr = np.zeros(len(false_dataset))\n",
    "\n",
    "    true_dataset['real'] = true_arr\n",
    "    false_dataset['real'] = false_arr\n",
    "    combined_dataset = pd.concat([true_dataset, false_dataset], ignore_index=True)\n",
    "    combined_dataset = combined_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return combined_dataset\n",
    "\n",
    "combined = combine_and_randomize_datasets(true_dataset, false_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7eaf1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = contractions.fix(text)                         # Expand contractions\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode() # Remove non-ASCII chars\n",
    "    text = text.lower()                                   # Lowercase\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)           # Remove URLs\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)                     # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)                  # Keep only letters and spaces\n",
    "    text = re.sub(r\"\\b\\w{1}\\b\", \"\", text)                 # Remove single-letter words\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()              # Remove extra spaces\n",
    "    words = text.split()\n",
    "    # words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75733f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {}\n",
    "\n",
    "# def process_words_into_dict(text, words_dict):\n",
    "#     for word in text.split():\n",
    "#         if word not in words_dict:\n",
    "#             words_dict[word] = 1\n",
    "#         else:\n",
    "#             words_dict[word] += 1\n",
    "\n",
    "# for text in combined['text']:\n",
    "#     text = clean_text(text)\n",
    "# tfidf = calculate_tfidf(combined['text'])\n",
    "\n",
    "X = combined['text']\n",
    "y = combined['real'].to_list()\n",
    "\n",
    "test_x = X[:20]\n",
    "X = X[20:]\n",
    "\n",
    "test_y=y[:20]\n",
    "y=y[20:]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X)  # shape (n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Convert to dense and then to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e52acc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.unsqueeze(1)  # Per sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = NewsDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = NewsDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8177af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple Feedforward Model\n",
    "# class FakeNewsClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 100)\n",
    "#         self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = torch.sigmoid(self.fc2(x))\n",
    "#         return x\n",
    "\n",
    "class FakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "model = FakeNewsClassifier(input_dim=5000).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1f3a4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 71.5659\n",
      "Epoch 2 - Loss: 14.2064\n",
      "Epoch 3 - Loss: 6.7422\n",
      "Epoch 4 - Loss: 5.8403\n",
      "Epoch 5 - Loss: 4.2146\n",
      "Epoch 6 - Loss: 2.8628\n",
      "Epoch 7 - Loss: 1.0371\n",
      "Epoch 8 - Loss: 1.4660\n",
      "Epoch 9 - Loss: 3.5881\n",
      "Epoch 10 - Loss: 1.9631\n",
      "Epoch 11 - Loss: 0.8713\n",
      "Epoch 12 - Loss: 0.5663\n",
      "Epoch 13 - Loss: 0.6283\n",
      "Epoch 14 - Loss: 0.4269\n",
      "Epoch 15 - Loss: 0.5722\n",
      "Epoch 16 - Loss: 1.0008\n",
      "Epoch 17 - Loss: 1.7675\n",
      "Epoch 18 - Loss: 3.3333\n",
      "Epoch 19 - Loss: 1.4838\n",
      "Epoch 20 - Loss: 0.6453\n",
      "Epoch 21 - Loss: 0.5984\n",
      "Epoch 22 - Loss: 0.3890\n",
      "Epoch 23 - Loss: 0.4235\n",
      "Epoch 24 - Loss: 0.4727\n",
      "Epoch 25 - Loss: 0.3564\n",
      "Epoch 26 - Loss: 0.4790\n",
      "Epoch 27 - Loss: 0.3820\n",
      "Epoch 28 - Loss: 0.5263\n",
      "Epoch 29 - Loss: 0.4679\n",
      "Epoch 30 - Loss: 0.4026\n",
      "Epoch 31 - Loss: 0.3833\n",
      "Epoch 32 - Loss: 0.4551\n",
      "Epoch 33 - Loss: 0.7018\n",
      "Epoch 34 - Loss: 1.4880\n",
      "Epoch 35 - Loss: 2.1392\n",
      "Epoch 36 - Loss: 3.5972\n",
      "Epoch 37 - Loss: 0.9349\n",
      "Epoch 38 - Loss: 0.4959\n",
      "Epoch 39 - Loss: 0.5643\n",
      "Epoch 40 - Loss: 0.5420\n",
      "Epoch 41 - Loss: 0.4308\n",
      "Epoch 42 - Loss: 0.4088\n",
      "Epoch 43 - Loss: 0.2972\n",
      "Epoch 44 - Loss: 0.4456\n",
      "Epoch 45 - Loss: 0.4428\n",
      "Epoch 46 - Loss: 0.3631\n",
      "Epoch 47 - Loss: 0.3780\n",
      "Epoch 48 - Loss: 0.3985\n",
      "Epoch 49 - Loss: 0.4524\n",
      "Epoch 50 - Loss: 0.4674\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model\n",
    "        outputs = model(batch_X)\n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d89cb4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)  # Ensure inputs are on model's device\n",
    "    y_test_tensor = y_test_tensor.to(device)  # Ensure labels are on the same device\n",
    "\n",
    "    preds = model(X_test_tensor).squeeze()\n",
    "    #print(f\"average pred: {preds.mean().item()}\")\n",
    "    preds_label = (preds > 0.5).int()\n",
    "    accuracy = (preds_label == y_test_tensor.int()).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "806b3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred 0.0 testing article: If you were to believe Barack Hussein Obama, Hillary Clinton, Bernie Sanders, the Democrats and RINO s in Congress, the only videos you should find on these poor persecuted migrants phones would be of tearful good-byes to families in their beloved home land. Not so fast You only have to watch this one video  to know, these aren t your usual  persecuted  migrants invading Europe.Just watch this video, and you ll see what we mean:https://youtu.be/silF8UT4mTE\n",
      "Prediction: tensor([[0.]], device='cuda:0') \n",
      " Is True tensor([[False]], device='cuda:0') was actually: False\n"
     ]
    }
   ],
   "source": [
    "def predict_news_article(article_text, vectorizer, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Vectorize input string\n",
    "        tfidf_vector = vectorizer.transform([article_text])\n",
    "        tfidf_tensor = torch.tensor(tfidf_vector.toarray(), dtype=torch.float32).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(tfidf_tensor)\n",
    "    \n",
    "        return output, output > 0.5\n",
    "\n",
    "# test_article = \"The government has announced a new plan to build solar-powered roads by 2050...\"\n",
    "# test_article=false_dataset['text'][123]\n",
    "idx = 9\n",
    "test_article = test_x[idx]\n",
    "test_article_pred = test_y[idx]\n",
    "print(f\"pred {test_article_pred} testing article: {test_article}\")\n",
    "\n",
    "prediction, is_true = predict_news_article(test_article, vectorizer, model)\n",
    "print(f\"Prediction: {prediction} \\n Is True {is_true} was actually: {test_article_pred>0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
