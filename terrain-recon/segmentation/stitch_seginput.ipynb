{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd# import everything ml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import contractions\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "from PIL import ImageDraw\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def filter_and_move_images(source_dir, dest_dir, suffix=\"_i2.png\"):\n",
    "    \"\"\"\n",
    "    Finds all files in the source directory ending with a specific suffix\n",
    "    and moves them to the destination directory.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): The path to the folder containing the original images.\n",
    "        dest_dir (str): The path to the folder where filtered images will be moved.\n",
    "        suffix (str): The ending string to filter files by (e.g., \"_i2.png\").\n",
    "    \"\"\"\n",
    "    # 1. Check if the source directory exists\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print(f\"‚ùå Error: Source folder not found at '{source_dir}'\")\n",
    "        return\n",
    "\n",
    "    # 2. Create the destination directory if it doesn't exist\n",
    "    if not os.path.exists(dest_dir):\n",
    "        print(f\"Destination folder not found. Creating it at: '{dest_dir}'\")\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    print(f\"üîç Searching for files ending with '{suffix}' in '{source_dir}'...\")\n",
    "\n",
    "    # 3. Find and move the files\n",
    "    files_moved = 0\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(suffix):\n",
    "            source_path = os.path.join(source_dir, filename)\n",
    "            destination_path = os.path.join(dest_dir, filename)\n",
    "            \n",
    "            # Move the file\n",
    "            shutil.move(source_path, destination_path)\n",
    "            print(f\"  -> Moved '{filename}'\")\n",
    "            files_moved += 1\n",
    "\n",
    "    print(f\"\\n‚úÖ Done! Moved a total of {files_moved} files.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- USER INPUT ---\n",
    "    # ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è **IMPORTANT: UPDATE THESE FOLDER PATHS** ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
    "    \n",
    "    # The folder where all your original images are currently located.\n",
    "    source_folder = \"./data/terrain_reconstruction/_dataset\"\n",
    "    \n",
    "    # The folder where you want the filtered '_i2.png' images to go.\n",
    "    # This will be created if it doesn't exist.\n",
    "    destination_folder = \"./data/terrain_reconstruction/segmentation_maps_folder\"\n",
    "\n",
    "    # ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è **IMPORTANT: UPDATE THESE FOLDER PATHS** ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è\n",
    "\n",
    "    # filter_and_move_images(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: Directory not found or is empty at '../../data/terrain_reconstruction/segmentation_maps_folder'.\n",
      "Please create the folder, add your images, or update the 'image_dir' variable.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.auto import tqdm # Import tqdm for progress bars\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Model Architecture (No changes here)\n",
    "# ==============================================================================\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        self.encoder1 = self.conv_block(in_channels, 64, batch_norm=False)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        self.encoder5 = self.conv_block(512, 512)\n",
    "        self.encoder6 = self.conv_block(512, 512)\n",
    "        self.encoder7 = self.conv_block(512, 512)\n",
    "        self.bottleneck = nn.Sequential(nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU())\n",
    "        self.decoder1 = self.deconv_block(512, 512, dropout=True)\n",
    "        self.decoder2 = self.deconv_block(1024, 512, dropout=True)\n",
    "        self.decoder3 = self.deconv_block(1024, 512, dropout=True)\n",
    "        self.decoder4 = self.deconv_block(1024, 512)\n",
    "        self.decoder5 = self.deconv_block(1024, 256)\n",
    "        self.decoder6 = self.deconv_block(512, 128)\n",
    "        self.decoder7 = self.deconv_block(256, 64)\n",
    "        self.final_layer = nn.Sequential(nn.ConvTranspose2d(128, out_channels, 4, 2, 1), nn.Tanh())\n",
    "    def conv_block(self, in_channels, out_channels, batch_norm=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False), nn.LeakyReLU(0.2)]\n",
    "        if batch_norm: layers.insert(1, nn.BatchNorm2d(out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    def deconv_block(self, in_channels, out_channels, dropout=False):\n",
    "        layers = [nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU()]\n",
    "        if dropout: layers.append(nn.Dropout(0.5))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        e1=self.encoder1(x);e2=self.encoder2(e1);e3=self.encoder3(e2);e4=self.encoder4(e3)\n",
    "        e5=self.encoder5(e4);e6=self.encoder6(e5);e7=self.encoder7(e6)\n",
    "        bottle=self.bottleneck(e7)\n",
    "        d1=torch.cat([self.decoder1(bottle),e7],1);d2=torch.cat([self.decoder2(d1),e6],1)\n",
    "        d3=torch.cat([self.decoder3(d2),e5],1);d4=torch.cat([self.decoder4(d3),e4],1)\n",
    "        d5=torch.cat([self.decoder5(d4),e3],1);d6=torch.cat([self.decoder6(d5),e2],1)\n",
    "        d7=torch.cat([self.decoder7(d6),e1],1)\n",
    "        return self.final_layer(d7)\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=6):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, 4, 1, 1, bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 1, 4, 1, 1)\n",
    "        )\n",
    "    def forward(self, x, y=None):\n",
    "        out = torch.cat([x, y], dim=1) if y is not None else x\n",
    "        return self.model(out)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Custom Dataset for Your Images\n",
    "# ==============================================================================\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_size=256):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        return self.transform(image)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Part 1: Seamless Tile Generator\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Hyperparameters & User Input ---\n",
    "image_dir = \"../../data/terrain_reconstruction/segmentation_maps_folder\"\n",
    "image_size = 256\n",
    "noise_dim = 100\n",
    "batch_size_seamless = 16\n",
    "epochs_seamless = 100\n",
    "lr_seamless = 0.0002\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "if not os.path.exists(image_dir) or not os.listdir(image_dir):\n",
    "    print(f\"‚ùå Error: Directory not found or is empty at '{image_dir}'.\")\n",
    "    print(\"Please create the folder, add your images, or update the 'image_dir' variable.\")\n",
    "else:\n",
    "    seamless_dataset = CustomImageDataset(image_dir=image_dir, image_size=image_size)\n",
    "    seamless_loader = DataLoader(seamless_dataset, batch_size=batch_size_seamless, shuffle=True)\n",
    "\n",
    "    seamless_gen = UNetGenerator(in_channels=noise_dim, out_channels=3).to(device)\n",
    "    seamless_disc = PatchDiscriminator(in_channels=3).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen_seamless = optim.Adam(seamless_gen.parameters(), lr=lr_seamless, betas=(0.5, 0.999))\n",
    "    optimizer_disc_seamless = optim.Adam(seamless_disc.parameters(), lr=lr_seamless, betas=(0.5, 0.999))\n",
    "\n",
    "    print(f\"üöÄ Starting Seamless GAN Training with {len(seamless_dataset)} images...\")\n",
    "    for epoch in range(epochs_seamless):\n",
    "        # --- ‚ú® ADDED: tqdm progress bar ---\n",
    "        progress_bar = tqdm(enumerate(seamless_loader), total=len(seamless_loader), desc=f\"Epoch {epoch+1}/{epochs_seamless}\")\n",
    "        for i, real_images in progress_bar:\n",
    "            real_images = real_images.to(device)\n",
    "            noise = torch.randn(real_images.size(0), noise_dim, 1, 1, device=device).repeat(1, 1, image_size, image_size)\n",
    "            \n",
    "            optimizer_disc_seamless.zero_grad()\n",
    "            fake_images = seamless_gen(noise)\n",
    "            disc_real = seamless_disc(real_images)\n",
    "            disc_fake = seamless_disc(fake_images.detach())\n",
    "            loss_disc = (criterion(disc_real, torch.ones_like(disc_real)) + criterion(disc_fake, torch.zeros_like(disc_fake)))/2\n",
    "            loss_disc.backward()\n",
    "            optimizer_disc_seamless.step()\n",
    "\n",
    "            optimizer_gen_seamless.zero_grad()\n",
    "            disc_fake = seamless_disc(fake_images)\n",
    "            loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            loss_gen.backward()\n",
    "            optimizer_gen_seamless.step()\n",
    "            \n",
    "            # --- ‚ú® ADDED: Update progress bar with current loss ---\n",
    "            progress_bar.set_postfix(loss_D=f\"{loss_disc.item():.4f}\", loss_G=f\"{loss_gen.item():.4f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Part 2: Conditional Stitching GAN\n",
    "# ==============================================================================\n",
    "\n",
    "class StitchingDataset(Dataset):\n",
    "    def __init__(self, image_paths, size, stitch_width):\n",
    "        self.image_paths = image_paths\n",
    "        self.size = size\n",
    "        self.stitch_width = stitch_width\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((size, size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        full_image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        full_image = self.transform(full_image)\n",
    "        conditional_strip = torch.zeros_like(full_image)\n",
    "        conditional_strip[:, :, :self.stitch_width] = full_image[:, :, :self.stitch_width]\n",
    "        return conditional_strip, full_image\n",
    "\n",
    "stitch_width = 32\n",
    "batch_size_stitch = 16\n",
    "epochs_stitch = 100\n",
    "lr_stitch = 0.0002\n",
    "\n",
    "if os.path.exists(image_dir) and os.listdir(image_dir):\n",
    "    stitch_dataset = StitchingDataset(seamless_dataset.image_paths, image_size, stitch_width)\n",
    "    stitch_loader = DataLoader(stitch_dataset, batch_size=batch_size_stitch, shuffle=True)\n",
    "\n",
    "    stitch_gen = UNetGenerator(in_channels=3, out_channels=3).to(device)\n",
    "    stitch_disc = PatchDiscriminator(in_channels=6).to(device)\n",
    "    optimizer_gen_stitch = optim.Adam(stitch_gen.parameters(), lr=lr_stitch, betas=(0.5, 0.999))\n",
    "    optimizer_disc_stitch = optim.Adam(stitch_disc.parameters(), lr=lr_stitch, betas=(0.5, 0.999))\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    print(f\"\\nüöÄ Starting Stitching GAN Training with {len(stitch_dataset)} images...\")\n",
    "    for epoch in range(epochs_stitch):\n",
    "        # --- ‚ú® ADDED: tqdm progress bar ---\n",
    "        progress_bar = tqdm(enumerate(stitch_loader), total=len(stitch_loader), desc=f\"Epoch {epoch+1}/{epochs_stitch}\")\n",
    "        for i, (cond_image, real_image) in progress_bar:\n",
    "            cond_image, real_image = cond_image.to(device), real_image.to(device)\n",
    "\n",
    "            optimizer_disc_stitch.zero_grad()\n",
    "            fake_image = stitch_gen(cond_image)\n",
    "            disc_real = stitch_disc(cond_image, real_image)\n",
    "            disc_fake = stitch_disc(cond_image, fake_image.detach())\n",
    "            loss_disc = (criterion(disc_real, torch.ones_like(disc_real)) + criterion(disc_fake, torch.zeros_like(disc_fake))) / 2\n",
    "            loss_disc.backward()\n",
    "            optimizer_disc_stitch.step()\n",
    "\n",
    "            optimizer_gen_stitch.zero_grad()\n",
    "            disc_fake = stitch_disc(cond_image, fake_image)\n",
    "            loss_gen_gan = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            loss_gen_l1 = l1_loss(fake_image, real_image) * 100\n",
    "            loss_gen = loss_gen_gan + loss_gen_l1\n",
    "            loss_gen.backward()\n",
    "            optimizer_gen_stitch.step()\n",
    "            \n",
    "            # --- ‚ú® ADDED: Update progress bar with current loss ---\n",
    "            progress_bar.set_postfix(loss_D=f\"{loss_disc.item():.4f}\", loss_G=f\"{loss_gen.item():.4f}\", loss_L1=f\"{loss_gen_l1.item():.4f}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Stitching GAN Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.save(stitch_gen.state_dict(), \"../../models/stitch_gen.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stitch_width' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m left_tile = seamless_gen(noise).detach().cpu()\n\u001b[32m      4\u001b[39m right_cond = torch.zeros_like(left_tile)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m right_cond[:, :, :stitch_width] = left_tile[:, :, -\u001b[43mstitch_width\u001b[49m:]\n\u001b[32m      6\u001b[39m right_tile = stitch_gen(right_cond.to(device)).detach().cpu()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Debugging: Print shapes\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'stitch_width' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(1, noise_dim, 1, 1, device=device).repeat(1, 1, image_size, image_size)\n",
    "    left_tile = seamless_gen(noise).detach().cpu()\n",
    "    right_cond = torch.zeros_like(left_tile)\n",
    "    right_cond[:, :, :stitch_width] = left_tile[:, :, -stitch_width:]\n",
    "    right_tile = stitch_gen(right_cond.to(device)).detach().cpu()\n",
    "\n",
    "    # Debugging: Print shapes\n",
    "    print(\"Left tile shape:\", left_tile.shape)\n",
    "    print(\"Right tile shape:\", right_tile.shape)\n",
    "\n",
    "    # Ensure dimensions match for concatenation\n",
    "    left_tile_cropped = left_tile[:, :, :, :-stitch_width]\n",
    "    print(\"Left tile cropped shape:\", left_tile_cropped.shape)\n",
    "\n",
    "    stitched_image = torch.cat([left_tile_cropped, right_tile], dim=3)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    stitched_image_display = (stitched_image[0].permute(1, 2, 0) + 1) / 2\n",
    "    plt.imshow(stitched_image_display.clamp(0, 1))\n",
    "    plt.title('Two Generated Maps Stitched Together')\n",
    "    plt.axvline(x=image_size - stitch_width - 0.5, color='r', linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 15:03:40.013933: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 15:03:40.116910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753999420.158971 2567133 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753999420.170998 2567133 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753999420.259791 2567133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999420.259800 2567133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999420.259801 2567133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999420.259802 2567133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-31 15:03:40.270733: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images for training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Path to your prepared segmentation maps\n",
    "DATA_FOLDER = \"./data/terrain_reconstruction/segmentation_maps_folder\"\n",
    "\n",
    "# Get a list of all your image file paths once at the start\n",
    "image_paths = [os.path.join(DATA_FOLDER, f) for f in os.listdir(DATA_FOLDER) if f.endswith('.png')]\n",
    "print(f\"Found {len(image_paths)} images for training.\")\n",
    "\n",
    "def load_real_samples(batch_size):\n",
    "    \"\"\"\n",
    "    Loads a random batch of real terrain images from your folder.\n",
    "    \"\"\"\n",
    "    # Choose random indices to create a batch\n",
    "    random_indices = np.random.randint(0, len(image_paths), batch_size)\n",
    "    \n",
    "    batch_images = []\n",
    "    for i in random_indices:\n",
    "        # Load and decode the image\n",
    "        img = tf.io.read_file(image_paths[i])\n",
    "        # Decode as grayscale, channels=1\n",
    "        img = tf.image.decode_png(img, channels=1) \n",
    "        # Resize to the model's expected input\n",
    "        img = tf.image.resize(img, [IMG_ROWS, IMG_COLS]) \n",
    "        batch_images.append(img)\n",
    "        \n",
    "    # Convert list of tensors to a single tensor\n",
    "    X = tf.stack(batch_images)\n",
    "    \n",
    "    # Normalize pixel values from [0, 255] to [-1, 1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    \n",
    "    # Create \"real\" class labels (value of 1)\n",
    "    y = np.ones((batch_size, 1))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# --- In your training loop ---\n",
    "# Replace the old call:\n",
    "# X_real, y_real = generate_real_samples(half_batch)\n",
    "\n",
    "# With the new one:\n",
    "# X_real, y_real = load_real_samples(half_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 15:07:16.242312: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 15:07:16.250291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753999636.258731 2579296 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753999636.261348 2579296 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753999636.269156 2579296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999636.269162 2579296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999636.269163 2579296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753999636.269164 2579296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-31 15:07:16.271769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 5000 images for training in './data/terrain_reconstruction/segmentation_maps_folder'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1753999637.346182 2579296 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5069 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753999637.934435 2579296 service.cc:152] XLA service 0x5cb3fe9938a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753999637.934447 2579296 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2025-07-31 15:07:17.945284: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753999637.964322 2579296 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "I0000 00:00:1753999639.348248 2579296 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-07-31 15:07:21.546339: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-input.6 = (f32[16,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,64,64]{3,2,1,0} %bitcast.581, f32[128,128,4,4]{3,2,1,0} %bitcast.588), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"Generator_1/conv2d_transpose_2_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:21.559106: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.012845019s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-input.6 = (f32[16,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,64,64]{3,2,1,0} %bitcast.581, f32[128,128,4,4]{3,2,1,0} %bitcast.588), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"Generator_1/conv2d_transpose_2_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:24.755960: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-input.7 = (f32[16,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,128,128]{3,2,1,0} %bitcast.629, f32[128,128,4,4]{3,2,1,0} %bitcast.636), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"Generator_1/conv2d_transpose_3_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:27.789045: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 4.033150621s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-input.7 = (f32[16,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,128,128]{3,2,1,0} %bitcast.629, f32[128,128,4,4]{3,2,1,0} %bitcast.636), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"Generator_1/conv2d_transpose_3_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:30.415922: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.3 = (f32[16,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,256,256]{3,2,1,0} %bitcast.677, f32[1,128,7,7]{3,2,1,0} %bitcast.684, f32[1]{0} %bitcast.686), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:30.555055: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.139208476s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.3 = (f32[16,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,256,256]{3,2,1,0} %bitcast.677, f32[1,128,7,7]{3,2,1,0} %bitcast.684, f32[1]{0} %bitcast.686), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:35.033949: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-input.13 = (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.13150, f32[128,128,4,4]{3,2,1,0} %bitcast.13139), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"GAN_1/Generator_1/conv2d_transpose_2_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:36.055870: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.021980485s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-input.13 = (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.13150, f32[128,128,4,4]{3,2,1,0} %bitcast.13139), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"GAN_1/Generator_1/conv2d_transpose_2_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:39.917512: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-input.14 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0} %bitcast.13355, f32[128,128,4,4]{3,2,1,0} %bitcast.13344), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"GAN_1/Generator_1/conv2d_transpose_3_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:46.976106: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.058662178s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-input.14 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0} %bitcast.13355, f32[128,128,4,4]{3,2,1,0} %bitcast.13344), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"GAN_1/Generator_1/conv2d_transpose_3_1/conv_transpose\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:49.991452: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.15 = (f32[32,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[1,128,7,7]{3,2,1,0} %bitcast.13553, f32[1]{0} %bitcast.13612), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"GAN_1/Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:50.410855: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.419465946s\n",
      "Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.15 = (f32[32,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[1,128,7,7]{3,2,1,0} %bitcast.13553, f32[1]{0} %bitcast.13612), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"GAN_1/Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:51.410961: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.15 = (f32[32,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[1,128,7,7]{3,2,1,0} %bitcast.13553, f32[1]{0} %bitcast.13612), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"GAN_1/Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:52.684895: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.274002249s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.15 = (f32[32,1,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[1,128,7,7]{3,2,1,0} %bitcast.13553, f32[1]{0} %bitcast.13612), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"GAN_1/Generator_1/conv2d_3_1/convolution\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:56.962421: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-input.16 = (f32[32,64,129,129]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.12250, f32[128,64,5,5]{3,2,1,0} %bitcast.12252), window={size=5x5 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Discriminator_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:57.790026: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.827666108s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-input.16 = (f32[32,64,129,129]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.12250, f32[128,64,5,5]{3,2,1,0} %bitcast.12252), window={size=5x5 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Discriminator_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:07:59.667709: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-31 15:08:01.097407: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng25{k2=0,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:01.718598: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.621252407s\n",
      "Trying algorithm eng25{k2=0,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:02.718706: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng25{k2=2,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:03.278890: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.560250009s\n",
      "Trying algorithm eng25{k2=2,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:04.375337: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng2{k2=1,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:05.811062: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.435805866s\n",
      "Trying algorithm eng2{k2=1,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:06.811356: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng2{k2=2,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:07.848334: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.037215229s\n",
      "Trying algorithm eng2{k2=2,k3=0} for conv %cudnn-conv-bw-input.18 = (f32[32,128,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,256]{3,2,1,0} %bitcast.13616, f32[1,128,7,7]{3,2,1,0} %bitcast.13553), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:12.315074: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv.12 = (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13406, f32[128,128,4,4]{3,2,1,0} %bitcast.13344), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2D\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_transpose_3_1/conv_transpose/Conv2D\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:12.624792: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.309776546s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv.12 = (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13406, f32[128,128,4,4]{3,2,1,0} %bitcast.13344), window={size=4x4 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2D\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_transpose_3_1/conv_transpose/Conv2D\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:24.282744: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng48{k0=5,k2=4,k5=2,k14=3} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:24.606455: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.323779634s\n",
      "Trying algorithm eng48{k0=5,k2=4,k5=2,k14=3} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:25.606582: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng21{k2=0,k4=3,k5=1,k6=0,k7=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:25.852905: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.246402364s\n",
      "Trying algorithm eng21{k2=0,k4=3,k5=1,k6=0,k7=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:26.852971: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=3,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:27.287545: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.434593289s\n",
      "Trying algorithm eng1{k2=3,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:28.907792: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng20{k2=1,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:30.094679: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.186950412s\n",
      "Trying algorithm eng20{k2=1,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:31.094781: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=1,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-07-31 15:08:32.404937: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.310207861s\n",
      "Trying algorithm eng1{k2=1,k3=0} for conv %cudnn-conv-bw-filter.9 = (f32[1,128,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,256,256]{3,2,1,0} %bitcast.13562, f32[32,1,256,256]{3,2,1,0} %bitcast.13616), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/GAN_1/Generator_1/conv2d_3_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/software/Documents/.rianstuff/cosmos/env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch 1/20, Batch 78/156, d_loss=[0.687,0.687], g_loss=0.258\n",
      "> Epoch 1/20, Batch 156/156, d_loss=[0.692,0.692], g_loss=0.153\n",
      "> Epoch 2/20, Batch 78/156, d_loss=[0.707,0.707], g_loss=0.108\n",
      "> Epoch 2/20, Batch 156/156, d_loss=[0.749,0.750], g_loss=0.084\n",
      "> Epoch 3/20, Batch 78/156, d_loss=[0.856,0.858], g_loss=0.069\n",
      "> Epoch 3/20, Batch 156/156, d_loss=[1.044,1.048], g_loss=0.058\n",
      "> Epoch 4/20, Batch 78/156, d_loss=[1.269,1.273], g_loss=0.050\n",
      "> Epoch 4/20, Batch 156/156, d_loss=[1.485,1.489], g_loss=0.044\n",
      "> Epoch 5/20, Batch 78/156, d_loss=[1.677,1.680], g_loss=0.040\n",
      "> Epoch 5/20, Batch 156/156, d_loss=[1.843,1.846], g_loss=0.036\n",
      "> Epoch 6/20, Batch 78/156, d_loss=[1.987,1.990], g_loss=0.033\n",
      "> Epoch 6/20, Batch 156/156, d_loss=[2.114,2.116], g_loss=0.030\n",
      "> Epoch 7/20, Batch 78/156, d_loss=[2.225,2.228], g_loss=0.028\n",
      "> Epoch 7/20, Batch 156/156, d_loss=[2.325,2.327], g_loss=0.026\n",
      "> Epoch 8/20, Batch 78/156, d_loss=[2.415,2.417], g_loss=0.025\n",
      "> Epoch 8/20, Batch 156/156, d_loss=[2.497,2.499], g_loss=0.023\n",
      "> Epoch 9/20, Batch 78/156, d_loss=[2.572,2.574], g_loss=0.022\n",
      "> Epoch 9/20, Batch 156/156, d_loss=[2.641,2.642], g_loss=0.021\n",
      "> Epoch 10/20, Batch 78/156, d_loss=[2.704,2.706], g_loss=0.020\n",
      "> Epoch 10/20, Batch 156/156, d_loss=[2.764,2.765], g_loss=0.019\n",
      "\n",
      "--- Saving progress for epoch 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Accuracy real: 100.00%, fake: 0.00%\n",
      "> Epoch 11/20, Batch 78/156, d_loss=[3.951,3.972], g_loss=0.018\n",
      "> Epoch 11/20, Batch 156/156, d_loss=[3.954,3.965], g_loss=0.017\n",
      "> Epoch 12/20, Batch 78/156, d_loss=[3.966,3.974], g_loss=0.016\n",
      "> Epoch 12/20, Batch 156/156, d_loss=[3.980,3.985], g_loss=0.016\n",
      "> Epoch 13/20, Batch 78/156, d_loss=[3.994,3.999], g_loss=0.015\n",
      "> Epoch 13/20, Batch 156/156, d_loss=[4.009,4.012], g_loss=0.015\n",
      "> Epoch 14/20, Batch 78/156, d_loss=[4.023,4.026], g_loss=0.014\n",
      "> Epoch 14/20, Batch 156/156, d_loss=[4.037,4.039], g_loss=0.014\n",
      "> Epoch 15/20, Batch 78/156, d_loss=[4.050,4.053], g_loss=0.013\n",
      "> Epoch 15/20, Batch 156/156, d_loss=[4.063,4.065], g_loss=0.013\n",
      "> Epoch 16/20, Batch 78/156, d_loss=[4.076,4.078], g_loss=0.012\n",
      "> Epoch 16/20, Batch 156/156, d_loss=[4.089,4.091], g_loss=0.012\n",
      "> Epoch 17/20, Batch 78/156, d_loss=[4.101,4.103], g_loss=0.012\n",
      "> Epoch 17/20, Batch 156/156, d_loss=[4.113,4.115], g_loss=0.011\n",
      "> Epoch 18/20, Batch 78/156, d_loss=[4.125,4.127], g_loss=0.011\n",
      "> Epoch 18/20, Batch 156/156, d_loss=[4.137,4.138], g_loss=0.011\n",
      "> Epoch 19/20, Batch 78/156, d_loss=[4.148,4.150], g_loss=0.010\n",
      "> Epoch 19/20, Batch 156/156, d_loss=[4.159,4.161], g_loss=0.010\n",
      "> Epoch 20/20, Batch 78/156, d_loss=[4.170,4.172], g_loss=0.010\n",
      "> Epoch 20/20, Batch 156/156, d_loss=[4.181,4.182], g_loss=0.010\n",
      "\n",
      "--- Saving progress for epoch 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Accuracy real: 93.75%, fake: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 1. Define Model & Data Parameters\n",
    "\n",
    "# Image dimensions\n",
    "IMG_ROWS = 256\n",
    "IMG_COLS = 256\n",
    "CHANNELS = 1 # Grayscale segmentation maps\n",
    "\n",
    "# Latent space dimension (input for the generator)\n",
    "LATENT_DIM = 100\n",
    "\n",
    "# Path to your prepared segmentation maps\n",
    "DATA_FOLDER = \"./data/terrain_reconstruction/segmentation_maps_folder\"\n",
    "\n",
    "# Get a list of all your image file paths\n",
    "try:\n",
    "    image_paths = [os.path.join(DATA_FOLDER, f) for f in os.listdir(DATA_FOLDER) if f.endswith('.png')]\n",
    "    print(f\"‚úÖ Found {len(image_paths)} images for training in '{DATA_FOLDER}'.\")\n",
    "    assert len(image_paths) > 0, \"No images found. Did you run the data preparation script?\"\n",
    "except (FileNotFoundError, AssertionError) as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Please ensure the data preparation script has been run and the path is correct.\")\n",
    "    # Exit or handle error appropriately in a real script\n",
    "    image_paths = []\n",
    "\n",
    "\n",
    "## 2. Build the Generator Model\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    \"\"\"Builds the Generator model.\"\"\"\n",
    "    model = Sequential(name='Generator')\n",
    "    n_nodes = 256 * 16 * 16\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((16, 16, 256)))\n",
    "    # Upsample to 32x32, 64x64, 128x128, 256x256\n",
    "    for i in range(4):\n",
    "        model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    # Output layer\n",
    "    model.add(Conv2D(CHANNELS, (7, 7), activation='tanh', padding='same'))\n",
    "    return model\n",
    "\n",
    "## 3. Build the Discriminator Model\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    \"\"\"Builds the Discriminator model.\"\"\"\n",
    "    model = Sequential(name='Discriminator')\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "## 4. Build the Combined GAN Model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    \"\"\"Builds the combined GAN model.\"\"\"\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential(name='GAN')\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "## 5. Define Data Loading and Helper Functions\n",
    "\n",
    "def load_real_samples(batch_size):\n",
    "    \"\"\"Loads a random batch of real terrain images from your folder.\"\"\"\n",
    "    random_indices = np.random.randint(0, len(image_paths), batch_size)\n",
    "    batch_images = []\n",
    "    for i in random_indices:\n",
    "        img = tf.io.read_file(image_paths[i])\n",
    "        img = tf.image.decode_png(img, channels=CHANNELS)\n",
    "        img = tf.image.resize(img, [IMG_ROWS, IMG_COLS])\n",
    "        batch_images.append(img)\n",
    "    X = tf.stack(batch_images)\n",
    "    X = (X - 127.5) / 127.5 # Normalize to [-1, 1]\n",
    "    y = np.ones((batch_size, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    \"\"\"Generates points in the latent space.\"\"\"\n",
    "    return np.random.randn(latent_dim * n_samples).reshape(n_samples, latent_dim)\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    \"\"\"Generates 'fake' samples using the generator.\"\"\"\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input, verbose=0)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def save_plot(examples, epoch, n=5):\n",
    "    \"\"\"Saves a plot of generated images.\"\"\"\n",
    "    examples = (examples + 1) / 2.0 # Scale from [-1, 1] to [0, 1]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i, :, :, 0], cmap='terrain')\n",
    "    filename = f'generated_plot_e{epoch+1:03d}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "## 6. Define the Main Training Loop\n",
    "\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=200, n_batch=32):\n",
    "    \"\"\"Main training loop for the GAN.\"\"\"\n",
    "    bat_per_epo = int(len(image_paths) / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    print(\"\\n--- Starting Training ---\")\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            # Train discriminator\n",
    "            X_real, y_real = load_real_samples(half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "            # Train generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "            # Summarize loss\n",
    "            if (j + 1) % (bat_per_epo // 2) == 0: # Print twice per epoch\n",
    "                 print(f'> Epoch {i+1}/{n_epochs}, Batch {j+1}/{bat_per_epo}, d_loss=[{d_loss1:.3f},{d_loss2:.3f}], g_loss={g_loss:.3f}')\n",
    "\n",
    "        # Evaluate and save progress at the end of each epoch\n",
    "        if (i + 1) % 10 == 0: # Every 10 epochs\n",
    "            print(f\"\\n--- Saving progress for epoch {i+1} ---\")\n",
    "            X_real_eval, y_real_eval = load_real_samples(n_batch)\n",
    "            _, acc_real = d_model.evaluate(X_real_eval, y_real_eval, verbose=0)\n",
    "            X_fake_eval, y_fake_eval = generate_fake_samples(g_model, latent_dim, n_batch)\n",
    "            _, acc_fake = d_model.evaluate(X_fake_eval, y_fake_eval, verbose=0)\n",
    "            print(f'> Accuracy real: {acc_real*100:.2f}%, fake: {acc_fake*100:.2f}%')\n",
    "            save_plot(X_fake_eval, i, n=4)\n",
    "            g_model.save(f'generator_model_{i+1:03d}.h5')\n",
    "\n",
    "## 7. Create Models and Start Training\n",
    "\n",
    "# Create the discriminator\n",
    "d_model = build_discriminator((IMG_ROWS, IMG_COLS, CHANNELS))\n",
    "# Create the generator\n",
    "g_model = build_generator(LATENT_DIM)\n",
    "# Create the GAN\n",
    "gan_model = build_gan(g_model, d_model)\n",
    "\n",
    "# Start training\n",
    "# Note: n_epochs=200 is a good start. Real-world results might need 1000s of epochs.\n",
    "if image_paths:\n",
    "    train(g_model, d_model, gan_model, LATENT_DIM, n_epochs=20, n_batch=32)\n",
    "else:\n",
    "    print(\"\\nSkipping training because no image data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
