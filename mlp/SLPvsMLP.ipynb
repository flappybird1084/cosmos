{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmOpSxuh3CIF"
   },
   "source": [
    "**SLP vs MLP**\n",
    "\n",
    "In this activity you will compare the performance of single-layer perceptrons (SLPs) versus multilayer perceptrons (MLPs) on two different classification tasks: MNIST digit recognition and playing tic-tac-toe.\n",
    "\n",
    "To get started, run the setup script below. This script will load several different datasets into memory so it may take awhile to finish...be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "id": "o3W6lBvG3uux"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1bnBkKnOxhQJlMcPItHCKWnO1wTenRjEd\n",
      "To: /Users/rianbutala/rians-projects/Coding/Other/cosmos/mlp/content/datasets/MNIST_train_dataset_small.pkl\n",
      "100%|██████████| 47.7M/47.7M [00:09<00:00, 5.24MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1a-YMPj6rPkEfaP5F9k-5b4Gp-bQtQXLT\n",
      "To: /Users/rianbutala/rians-projects/Coding/Other/cosmos/mlp/content/datasets/MNIST_test_dataset_small.pkl\n",
      "100%|██████████| 7.92M/7.92M [00:00<00:00, 13.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hRgI_d0H8yDatEqWQxQTRXeasYYXtAIS\n",
      "To: /Users/rianbutala/rians-projects/Coding/Other/cosmos/mlp/content/datasets/tic_tac_toe_dataset.npz\n",
      "100%|██████████| 26.6k/26.6k [00:00<00:00, 3.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#from google.colab import drive\n",
    "import pickle\n",
    "import gdown\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device)  # For Apple Silicon\n",
    "\n",
    "# ------- uncomment to load full MNIST dataset through torchvision and downsamlpe to 1/5 original size\n",
    "# # Load MNIST dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# full_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# # Subsample 1/5 of the data while keeping class balance\n",
    "# indices_by_class = {i: [] for i in range(10)}\n",
    "# for idx, (_, label) in enumerate(full_train_dataset):\n",
    "#     indices_by_class[label] = indices_by_class.get(label, []) + [idx]\n",
    "# sampled_indices = []\n",
    "# for i in range(10):\n",
    "#     sampled_indices.extend(np.random.choice(indices_by_class[i], len(indices_by_class[i]) // 5, replace=False))\n",
    "# train_dataset = torch.utils.data.Subset(full_train_dataset, sampled_indices)\n",
    "# test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# ------- uncomment to save a reduced MNIST dataset to a file\n",
    "# # Save train_dataset and test_dataset to files\n",
    "# output_folder = \"/content/drive/My Drive/Public/datasets\"\n",
    "# train_dataset_file = os.path.join(output_folder, 'MNIST_train_dataset_small.pkl')\n",
    "# test_dataset_file = os.path.join(output_folder, 'MNIST_test_dataset_small.pkl')\n",
    "# with open(train_dataset_file, 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f)\n",
    "# with open(test_dataset_file, 'wb') as f:\n",
    "#     pickle.dump(test_dataset, f)\n",
    "\n",
    "\n",
    "# ---------- uncomment to load reduced MNIST data from blair Public folder ----------\n",
    "# Define Google Drive file IDs (Extract these from shareable links)\n",
    "train_file_id = \"1bnBkKnOxhQJlMcPItHCKWnO1wTenRjEd\"\n",
    "test_file_id = \"1a-YMPj6rPkEfaP5F9k-5b4Gp-bQtQXLT\"\n",
    "output_folder = \"./content/datasets\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure directory exists\n",
    "train_dataset_file = os.path.join(output_folder, 'MNIST_train_dataset_small.pkl')\n",
    "test_dataset_file = os.path.join(output_folder, 'MNIST_test_dataset_small.pkl')\n",
    "gdown.download(f\"https://drive.google.com/uc?id={train_file_id}\", train_dataset_file, quiet=False)\n",
    "gdown.download(f\"https://drive.google.com/uc?id={test_file_id}\", test_dataset_file, quiet=False)\n",
    "with open(train_dataset_file, 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open(test_dataset_file, 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ---------- uncomment to dowload tic tac toe data from blair Public folder ------------\n",
    "file_id = \"1hRgI_d0H8yDatEqWQxQTRXeasYYXtAIS\"  # Replace with actual file ID\n",
    "output_folder = \"./content/datasets\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure directory exists\n",
    "data_file = os.path.join(output_folder, \"tic_tac_toe_dataset.npz\")\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", data_file, quiet=False)\n",
    "data = np.load(data_file)\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "Xttt_train, yttt_train = X_flat, y_labels\n",
    "X_train_tensor = torch.tensor(Xttt_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(yttt_train, dtype=torch.long)\n",
    "\n",
    "#----- create the tic tac toe game ---------\n",
    "# Define Tic-Tac-Toe Board\n",
    "board = np.zeros(9)  # 1 for X, -1 for O, 0 for empty\n",
    "user_symbol = 1  # X\n",
    "ai_symbol = -1  # O\n",
    "\n",
    "# Load or define model\n",
    "input_size = 9\n",
    "num_classes = 9\n",
    "\n",
    "# Generate buttons for user input\n",
    "buttons = [widgets.Button(description=' ', layout=widgets.Layout(width='50px', height='50px')) for _ in range(9)]\n",
    "\n",
    "# Display the Tic-Tac-Toe board\n",
    "def display_board():\n",
    "    clear_output(wait=True)\n",
    "    board_layout = widgets.GridBox(children=buttons, layout=widgets.Layout(grid_template_columns='repeat(3, 50px)'))\n",
    "    display(board_layout)\n",
    "\n",
    "# Handle user move\n",
    "def on_button_click(i):\n",
    "    def click_callback(b):\n",
    "        global game_over\n",
    "        if board[i] == 0 and not game_over:  # If the spot is empty and the game is not over\n",
    "            board[i] = user_symbol\n",
    "            buttons[i].description = 'X'\n",
    "            buttons[i].disabled = True\n",
    "            if check_game_status():\n",
    "                return  # Stop AI move if game is over\n",
    "            ai_move()\n",
    "            check_game_status()\n",
    "    return click_callback\n",
    "\n",
    "# AI move\n",
    "def ai_move():\n",
    "    global game_over\n",
    "    if game_over:\n",
    "        return  # Prevent AI from moving if game is over\n",
    "\n",
    "    board_tensor = torch.tensor(board, dtype=torch.float32).unsqueeze(0)\n",
    "    logits = model(board_tensor).detach().numpy().flatten()\n",
    "    empty_indices = [i for i in range(9) if board[i] == 0]\n",
    "    if empty_indices:\n",
    "        best_move = max(empty_indices, key=lambda idx: logits[idx])\n",
    "        board[best_move] = ai_symbol\n",
    "        buttons[best_move].description = 'O'\n",
    "        buttons[best_move].disabled = True\n",
    "\n",
    "# Check for win/loss/draw\n",
    "def check_game_status():\n",
    "    global game_over\n",
    "    winning_combinations = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "    for combo in winning_combinations:\n",
    "        line = [board[i] for i in combo]\n",
    "        if sum(line) == 3:\n",
    "            print(\"You win!\")\n",
    "            disable_buttons()\n",
    "            game_over = True\n",
    "            return True\n",
    "        elif sum(line) == -3:\n",
    "            print(\"AI wins!\")\n",
    "            disable_buttons()\n",
    "            game_over = True\n",
    "            return True\n",
    "    if 0 not in board:\n",
    "        print(\"It's a draw!\")\n",
    "        disable_buttons()\n",
    "        game_over = True\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Disable buttons after game ends\n",
    "def disable_buttons():\n",
    "    for btn in buttons:\n",
    "        btn.disabled = True\n",
    "\n",
    "# Assign button callbacks\n",
    "for i in range(9):\n",
    "    buttons[i].on_click(on_button_click(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WTeQmVJAe3R"
   },
   "source": [
    "**QUESTION 1 PART A:**\n",
    "\n",
    "Let's start by training an SLP on the MNIST dataset to recognize hand written digits:\n",
    "\n",
    "\n",
    ">![](https://drive.google.com/uc?id=1OGQ6tS81rmoYQ7sA1E5bq6iE4aErB0aS)\n",
    "\n",
    "\n",
    "When you run the script below, the SLP will be trained to classify inputs as one of the digits 0-9. The network will be trained for 10 epochs (that is, 10 complete passes through the entire training set).You will then see a report of performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IURq-fjjzWsf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8099, Train Accuracy: 77.85%\n",
      "Epoch 2/10, Loss: 0.4344, Train Accuracy: 87.45%\n",
      "Epoch 3/10, Loss: 0.3780, Train Accuracy: 89.04%\n",
      "Epoch 4/10, Loss: 0.3429, Train Accuracy: 90.25%\n",
      "Epoch 5/10, Loss: 0.3282, Train Accuracy: 90.29%\n",
      "Epoch 6/10, Loss: 0.3164, Train Accuracy: 90.82%\n",
      "Epoch 7/10, Loss: 0.3039, Train Accuracy: 91.00%\n",
      "Epoch 8/10, Loss: 0.2977, Train Accuracy: 91.13%\n",
      "Epoch 9/10, Loss: 0.2887, Train Accuracy: 91.56%\n",
      "Epoch 10/10, Loss: 0.2866, Train Accuracy: 91.66%\n",
      "\n",
      "Validation Accuracy for each digit:\n",
      "Digit 0: 95.41%\n",
      "Digit 1: 97.53%\n",
      "Digit 2: 87.11%\n",
      "Digit 3: 88.02%\n",
      "Digit 4: 92.36%\n",
      "Digit 5: 87.78%\n",
      "Digit 6: 89.98%\n",
      "Digit 7: 92.80%\n",
      "Digit 8: 88.09%\n",
      "Digit 9: 87.12%\n",
      "Overall Test Accuracy: 90.73%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prompt user for hidden layer size\n",
    "hidden_units = 0 #int(input(\"Enter the number of units in the MLP hidden layer (0 for SLP): \"))\n",
    "\n",
    "# Define MLP or SLP model dynamically\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        if hidden_units > 0:\n",
    "            self.fc1 = nn.Linear(28*28, hidden_units)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_units, 10)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(28*28, 10)  # Single-layer perceptron (SLP)\n",
    "            self.relu = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = NeuralNet(hidden_units).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {correct/total*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            class_correct[label] += (predicted[i] == labels[i]).item()\n",
    "            class_total[label] += 1\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print accuracy for each digit\n",
    "print(\"\\nValidation Accuracy for each digit:\")\n",
    "for i in range(10):\n",
    "    acc = 100 * class_correct[i] / class_total[i]\n",
    "    print(f\"Digit {i}: {acc:.2f}%\")\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f\"Overall Test Accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "slpota = correct / total * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOD-V-tyLrig"
   },
   "source": [
    "**QUESTION 1 PART B:**\n",
    "\n",
    "Now let's train an MLP with one hidden layer on the same MNIST dataset:\n",
    "\n",
    ">![](https://drive.google.com/uc?id=1XHSay4fcjHbpoFYn8jR_9QO2nmRN3DBY)\n",
    "\n",
    "When you run the script below, you will be prompted to enter the number of units for the MLP's hidden layer. Then the network will be trained for 10 epochs (that is, 10 complete passes through the entire training set) using the number of hidden units you selected.\n",
    "\n",
    "You should find that by using more hidden units, you can improve the Overall Test Accuracy. Keep running the script until you find a number of hidden units that increases the Overall Test Accuracy by at least 5% higher than the result you obtained above for the SLP with no hidden layer (for example, if your SLP achieved 88% accuracy then train the MLP to at least 93% accuracy).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-JL67Q05I4CD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7188, Train Accuracy: 79.78%\n",
      "Epoch 2/10, Loss: 0.3738, Train Accuracy: 88.77%\n",
      "Epoch 3/10, Loss: 0.3101, Train Accuracy: 91.01%\n",
      "Epoch 4/10, Loss: 0.2803, Train Accuracy: 91.46%\n",
      "Epoch 5/10, Loss: 0.2481, Train Accuracy: 92.64%\n",
      "Epoch 6/10, Loss: 0.2236, Train Accuracy: 93.30%\n",
      "Epoch 7/10, Loss: 0.2007, Train Accuracy: 94.01%\n",
      "Epoch 8/10, Loss: 0.1754, Train Accuracy: 94.86%\n",
      "Epoch 9/10, Loss: 0.1572, Train Accuracy: 95.47%\n",
      "Epoch 10/10, Loss: 0.1398, Train Accuracy: 95.90%\n",
      "\n",
      "Validation Accuracy for each digit:\n",
      "Digit 0: 99.08%\n",
      "Digit 1: 97.71%\n",
      "Digit 2: 92.93%\n",
      "Digit 3: 91.09%\n",
      "Digit 4: 94.70%\n",
      "Digit 5: 90.58%\n",
      "Digit 6: 94.78%\n",
      "Digit 7: 94.07%\n",
      "Digit 8: 94.97%\n",
      "Digit 9: 91.18%\n",
      "Overall Test Accuracy: 94.17%\n"
     ]
    }
   ],
   "source": [
    "# Prompt user for hidden layer size\n",
    "hidden_units = int(input(\"Enter the number of units in the MLP hidden layer (0 for SLP): \"))\n",
    "\n",
    "# Define MLP or SLP model dynamically\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        if hidden_units > 0:\n",
    "            self.fc1 = nn.Linear(28*28, hidden_units)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_units, 10)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(28*28, 10)  # Single-layer perceptron (SLP)\n",
    "            self.relu = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = NeuralNet(hidden_units).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {correct/total*100:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            class_correct[label] += (predicted[i] == labels[i]).item()\n",
    "            class_total[label] += 1\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print accuracy for each digit\n",
    "print(\"\\nValidation Accuracy for each digit:\")\n",
    "for i in range(10):\n",
    "    acc = 100 * class_correct[i] / class_total[i]\n",
    "    print(f\"Digit {i}: {acc:.2f}%\")\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f\"Overall Test Accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNNuSho0EgK6"
   },
   "source": [
    "**QUESTION 2 PART A**\n",
    "\n",
    "Now we will train an SLP to play tic-tac-toe by converting board positions into images:\n",
    ">![](https://drive.google.com/uc?id=11Db63-PeVkNDJuveRFExzZhS0npbFEBL)\n",
    "\n",
    "There are only 6,617 unique tic-tac-toe board positions, so we can train the network on ALL possible board positions. This means that we will only have a training set and no testing set.\n",
    "\n",
    "When you run the script below, the network will be trained for 1000 epochs You will then be able to play games of tic-tac-toe against the trained SLP network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YXaF4mWHfK2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2.0365, Accuracy: 26.36%\n",
      "Epoch [200/1000], Loss: 2.0331, Accuracy: 26.25%\n",
      "Epoch [300/1000], Loss: 2.0329, Accuracy: 26.24%\n",
      "Epoch [400/1000], Loss: 2.0329, Accuracy: 26.22%\n",
      "Epoch [500/1000], Loss: 2.0329, Accuracy: 26.24%\n",
      "Epoch [600/1000], Loss: 2.0329, Accuracy: 26.25%\n",
      "Epoch [700/1000], Loss: 2.0329, Accuracy: 26.25%\n",
      "Epoch [800/1000], Loss: 2.0329, Accuracy: 26.25%\n",
      "Epoch [900/1000], Loss: 2.0329, Accuracy: 26.25%\n",
      "Epoch [1000/1000], Loss: 2.0329, Accuracy: 26.25%\n"
     ]
    }
   ],
   "source": [
    "# Prompt user for hidden layer size\n",
    "hidden_units = 0 #int(input(\"Enter the number of units in the hidden layer (0 for SLP): \"))\n",
    "\n",
    "# Define Model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        if hidden_units > 0:\n",
    "            self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(input_size, num_classes)  # SLP case\n",
    "            self.relu = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = X_train_tensor.shape[1]\n",
    "num_classes = len(torch.unique(y_train_tensor))\n",
    "model = NeuralNet(input_size, hidden_units, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_train_tensor).sum().item() / y_train_tensor.size(0) * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "Q2_slpacc = accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVi-b-9sGMD7"
   },
   "source": [
    "**QUESTION 2 PART B**\n",
    "\n",
    "What level of accuracy did the SLP network achieve? How well do you think this network will be able to play tic-tac-toe? Let's find out! Run the script below to play games against the SLP bot. Click in a square to make your move. Play as many times as you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "J4fITpmdkgCo"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39356d65f5547dea20f243a8bccfe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Button(description=' ', layout=Layout(height='50px', width='50px'), style=ButtonStyle()), Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_over = False  # Flag to track if the game is over\n",
    "board = np.zeros(9)  # 1 for X, -1 for O, 0 for empty\n",
    "for btn in buttons:\n",
    "    btn.description = ' '\n",
    "    btn.disabled = False\n",
    "display_board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEa5v2-UG9kr"
   },
   "source": [
    "**QUESTION 2 PART C**\n",
    "\n",
    "Now let's train an MLP with one hidden layer to play tic-tac-toe:\n",
    "\n",
    ">![](https://drive.google.com/uc?id=1aMu1Geb6RwMnUlvnBFUWmB2m8Oat3dVU)\n",
    "\n",
    "When you run the script you will be prompted to enter the number of hidden layer units. Can you train the network to be 100% accurate with enough hidden units?\n",
    "\n",
    "After training to near 100% accuracy, try playing against the AI again below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8Ndx9i_CGGsU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2004, Accuracy: 94.98%\n",
      "Epoch [200/1000], Loss: 0.0934, Accuracy: 98.59%\n",
      "Epoch [300/1000], Loss: 0.0470, Accuracy: 99.64%\n",
      "Epoch [400/1000], Loss: 0.0251, Accuracy: 99.97%\n",
      "Epoch [500/1000], Loss: 0.0147, Accuracy: 100.00%\n",
      "Epoch [600/1000], Loss: 0.0094, Accuracy: 100.00%\n",
      "Epoch [700/1000], Loss: 0.0064, Accuracy: 100.00%\n",
      "Epoch [800/1000], Loss: 0.0047, Accuracy: 100.00%\n",
      "Epoch [900/1000], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [1000/1000], Loss: 0.0027, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Prompt user for hidden layer size\n",
    "hidden_units = int(input(\"Enter the number of units in the hidden layer (0 for SLP): \"))\n",
    "input_size = X_train_tensor.shape[1]\n",
    "num_classes = len(torch.unique(y_train_tensor))\n",
    "model = NeuralNet(input_size, hidden_units, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_train_tensor).sum().item() / y_train_tensor.size(0) * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lesFjlFrJPYN"
   },
   "source": [
    "Play against the AI again by running this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MEkAApTqIo4e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457937debfd84f038f1d201f6e5306e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Button(description=' ', layout=Layout(height='50px', width='50px'), style=ButtonStyle()), Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_over = False  # Flag to track if the game is over\n",
    "board = np.zeros(9)  # 1 for X, -1 for O, 0 for empty\n",
    "for btn in buttons:\n",
    "    btn.description = ' '\n",
    "    btn.disabled = False\n",
    "display_board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSREAmHuKqOE"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
